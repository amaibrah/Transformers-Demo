{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zero-shot Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main goal of zero-shot classification is to be able to classify text without using any labeled data and without seeing labelled text. Zero-shot classification models can be used on text of a different domain that is was not initially trained on. This makes these types of models best for generalized topics overall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to check gpu usage\n",
    "from GPUtil import showUtilization as gpu_usage\n",
    "gpu_usage()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env CUDA_VISIBLE_DEVICES= 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#packages that need to be installed\n",
    "!pip3 install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import needed packages\n",
    "from transformers import pipeline, AutoModelForSequenceClassification, AutoTokenizer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before looking further under the hood of the model, will use Hugging Face's pipline module to see how it works. The pipeline allows for mdoels to be tested out where only the needed inputs are needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier= pipeline(task=\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
    "\n",
    "input_sequence = \"I love traveling\"\n",
    "label_candidate = ['travel', 'cooking', 'entertainment', 'dancing', 'technology']\n",
    "classifier(input_sequence, label_candidate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result above shows the label that is most likely to be related out of the list of labels. This is a single-label version of zero-shot classification.\n",
    "\n",
    "Zero-shot classification can also be used for multi-label classification where it tests the probablity of each label being similar to the statement or input. Each probability score is calculated independently instead of together. This is tested below while still using the pipeline function above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "\n",
    "text_piece = \"I love traveling\"\n",
    "labels = ['travel', 'cooking', 'entertainment', 'dancing', 'technology']\n",
    "\n",
    "predictions = classifier(text_piece, labels, multi_label=True)\n",
    "pprint.pprint(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When comparing the single-label to the multi-label, \"travel\" is still the label that is the msot related to the statement. The multi-class version shows that \"entertainment\" can also be highly related to the statement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select the pretrained model with AutoModelForSequenceClassification\n",
    "model= AutoModelForSequenceClassification.from_pretrained('joeddav/xlm-roberta-large-xnli')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#configuration feature used to see how the model works and what the pretrained settings are set as\n",
    "model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint= 'joeddav/xlm-roberta-large-xnli'\n",
    "\n",
    "model= AutoModelForSequenceClassification.from_pretrained(checkpoint)\n",
    "tokenizer= AutoTokenizer.from_pretrained(checkpoint)\n",
    "\n",
    "#device= torch.device('cuda' if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "premise= input('Please enter a statement in English or any of the languages listed above: ')\n",
    "#allow for input of multiple labels at once instead of repeatedly asking\n",
    "labels= [str(x) for x in input(\"Please list the labels you would like to use for this classification. Use a comma to separate each word: \").split(', ')]\n",
    "\n",
    "output={}\n",
    "\n",
    "for i in labels:\n",
    "    x= tokenizer.encode(premise, i, return_tensors='pt', truncation_strategy='only_first')\n",
    "    logits= model(x.to(device))[0]\n",
    "\n",
    "    entail_contradiction_logits= logits[:, [0,2]]\n",
    "    probs= entail_contradiction_logits.softmax(dim=1)\n",
    "    output[i]= float(probs[:,1])\n",
    "\n",
    "#return results in order of probability of similarity\n",
    "def sort(d, reverse=False):\n",
    "    return dict(sorted(d.items(), key= lambda x: x[1], reverse=reverse))\n",
    "\n",
    "def display(d, show=True):\n",
    "    plt.barh(range(len(d)), d.values(), tick_label= d.keys())\n",
    "\n",
    "print(premise)\n",
    "print('')\n",
    "print(output)\n",
    "output.display(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('demoEnv': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "abab9fb3ef906d878718f3c698ddd49c743193d3b013b964c504f3fdd96ee333"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
